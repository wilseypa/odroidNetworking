diff -up a/drivers/infiniband/hw/qib/Makefile b/drivers/infiniband/hw/qib/Makefile
--- a/drivers/infiniband/hw/qib/Makefile	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/Makefile	2010-04-20 15:58:32.000000000 -0700
@@ -1,4 +1,4 @@
-ccflags-y += -DQIB_KERN_TYPE=0 -DQIB_IDSTR='"QLogic kernel.org driver"'
+EXTRA_CFLAGS += -DQIB_KERN_TYPE=0 -DQIB_IDSTR='"QLogic kernel.org driver"'
 
 obj-$(CONFIG_INFINIBAND_QIB) += ib_qib.o
 
diff -up a/drivers/infiniband/hw/qib/qib_cq.c b/drivers/infiniband/hw/qib/qib_cq.c
--- a/drivers/infiniband/hw/qib/qib_cq.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_cq.c	2010-04-20 16:11:40.000000000 -0700
@@ -236,11 +236,12 @@ struct ib_cq *qib_create_cq(struct ib_de
 		sz += sizeof(struct ib_uverbs_wc) * (entries + 1);
 	else
 		sz += sizeof(struct ib_wc) * (entries + 1);
-	wc = vmalloc_user(sz);
+	wc = vmalloc(sz);
 	if (!wc) {
 		ret = ERR_PTR(-ENOMEM);
 		goto bail_cq;
 	}
+	memset(wc, 0, sz);
 
 	/*
 	 * Return the address of the WC as the offset to mmap.
@@ -321,7 +322,7 @@ int qib_destroy_cq(struct ib_cq *ibcq)
 	struct qib_ibdev *dev = to_idev(ibcq->device);
 	struct qib_cq *cq = to_icq(ibcq);
 
-	flush_work(&cq->comptask);
+	flush_workqueue(qib_cq_wq);
 	spin_lock(&dev->n_cqs_lock);
 	dev->n_cqs_allocated--;
 	spin_unlock(&dev->n_cqs_lock);
@@ -395,11 +396,12 @@ int qib_resize_cq(struct ib_cq *ibcq, in
 		sz += sizeof(struct ib_uverbs_wc) * (cqe + 1);
 	else
 		sz += sizeof(struct ib_wc) * (cqe + 1);
-	wc = vmalloc_user(sz);
+	wc = vmalloc(sz);
 	if (!wc) {
 		ret = -ENOMEM;
 		goto bail;
 	}
+	memset(wc, 0, sz);
 
 	/* Check that we can write the offset to mmap. */
 	if (udata && udata->outlen >= sizeof(__u64)) {
diff -up a/drivers/infiniband/hw/qib/qib_diag.c b/drivers/infiniband/hw/qib/qib_diag.c
--- a/drivers/infiniband/hw/qib/qib_diag.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_diag.c	2010-04-20 15:58:32.000000000 -0700
@@ -140,7 +140,7 @@ static const struct file_operations diag
 
 static atomic_t diagpkt_count = ATOMIC_INIT(0);
 static struct cdev *diagpkt_cdev;
-static struct device *diagpkt_device;
+static struct class_device *diagpkt_class_dev;
 
 static ssize_t qib_diagpkt_write(struct file *fp, const char __user *data,
 				 size_t count, loff_t *off);
@@ -158,7 +158,7 @@ int qib_diag_add(struct qib_devdata *dd)
 	if (atomic_inc_return(&diagpkt_count) == 1) {
 		ret = qib_cdev_init(QIB_DIAGPKT_MINOR, "ipath_diagpkt",
 				    &diagpkt_file_ops, &diagpkt_cdev,
-				    &diagpkt_device);
+				    &diagpkt_class_dev);
 		if (ret)
 			goto done;
 	}
@@ -166,7 +166,7 @@ int qib_diag_add(struct qib_devdata *dd)
 	snprintf(name, sizeof(name), "ipath_diag%d", dd->unit);
 	ret = qib_cdev_init(QIB_DIAG_MINOR_BASE + dd->unit, name,
 			    &diag_file_ops, &dd->diag_cdev,
-			    &dd->diag_device);
+			    &dd->diag_class_dev);
 done:
 	return ret;
 }
@@ -178,9 +178,9 @@ void qib_diag_remove(struct qib_devdata 
 	struct qib_diag_client *dc;
 
 	if (atomic_dec_and_test(&diagpkt_count))
-		qib_cdev_cleanup(&diagpkt_cdev, &diagpkt_device);
+		qib_cdev_cleanup(&diagpkt_cdev, &diagpkt_class_dev);
 
-	qib_cdev_cleanup(&dd->diag_cdev, &dd->diag_device);
+	qib_cdev_cleanup(&dd->diag_cdev, &dd->diag_class_dev);
 
 	/*
 	 * Return all diag_clients of this device. There should be none,
diff -up a/drivers/infiniband/hw/qib/qib_file_ops.c b/drivers/infiniband/hw/qib/qib_file_ops.c
--- a/drivers/infiniband/hw/qib/qib_file_ops.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_file_ops.c	2010-04-20 15:58:32.000000000 -0700
@@ -52,15 +52,15 @@
 static int qib_open(struct inode *, struct file *);
 static int qib_close(struct inode *, struct file *);
 static ssize_t qib_write(struct file *, const char __user *, size_t, loff_t *);
-static ssize_t qib_aio_write(struct kiocb *, const struct iovec *,
-			     unsigned long, loff_t);
+static ssize_t qib_writev(struct file *, const struct iovec *,
+			  unsigned long , loff_t *);
 static unsigned int qib_poll(struct file *, struct poll_table_struct *);
 static int qib_mmapf(struct file *, struct vm_area_struct *);
 
 static const struct file_operations qib_file_ops = {
 	.owner = THIS_MODULE,
 	.write = qib_write,
-	.aio_write = qib_aio_write,
+	.writev = qib_writev,
 	.open = qib_open,
 	.release = qib_close,
 	.poll = qib_poll,
@@ -968,24 +968,33 @@ bail:
 }
 
 /*
- * qib_file_vma_fault - handle a VMA page fault.
+ * qib_file_vma_nopage - handle a VMA page fault.
  */
-static int qib_file_vma_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+static struct page *qib_file_vma_nopage(struct vm_area_struct *vma,
+					unsigned long address, int *type)
 {
-	struct page *page;
+	unsigned long offset = address - vma->vm_start;
+	struct page *page = NOPAGE_SIGBUS;
+	void *pageptr;
 
-	page = vmalloc_to_page((void *)(vmf->pgoff << PAGE_SHIFT));
+	/*
+	 * Convert the vmalloc address into a struct page.
+	 */
+	pageptr = (void *)(offset + (vma->vm_pgoff << PAGE_SHIFT));
+	page = vmalloc_to_page(pageptr);
 	if (!page)
-		return VM_FAULT_SIGBUS;
+		goto out;
 
+	/* Increment the reference count. */
 	get_page(page);
-	vmf->page = page;
-
-	return 0;
+	if (type)
+		*type = VM_FAULT_MINOR;
+out:
+	return page;
 }
 
 static struct vm_operations_struct qib_file_vm_ops = {
-	.fault = qib_file_vma_fault,
+	.nopage = qib_file_vma_nopage,
 };
 
 static int mmap_kvaddr(struct vm_area_struct *vma, u64 pgaddr,
@@ -1314,7 +1323,7 @@ static int init_subctxts(struct qib_devd
 		goto bail;
 	}
 
-	rcd->subctxt_uregbase = vmalloc_user(PAGE_SIZE * num_subctxts);
+	rcd->subctxt_uregbase = vmalloc(PAGE_SIZE * num_subctxts);
 	if (!rcd->subctxt_uregbase) {
 		ret = -ENOMEM;
 		goto bail;
@@ -1322,15 +1331,15 @@ static int init_subctxts(struct qib_devd
 	/* Note: rcd->rcvhdrq_size isn't initialized yet. */
 	size = ALIGN(dd->rcvhdrcnt * dd->rcvhdrentsize *
 		     sizeof(u32), PAGE_SIZE) * num_subctxts;
-	rcd->subctxt_rcvhdr_base = vmalloc_user(size);
+	rcd->subctxt_rcvhdr_base = vmalloc(size);
 	if (!rcd->subctxt_rcvhdr_base) {
 		ret = -ENOMEM;
 		goto bail_ureg;
 	}
 
-	rcd->subctxt_rcvegrbuf = vmalloc_user(rcd->rcvegrbuf_chunks *
-					      rcd->rcvegrbuf_size *
-					      num_subctxts);
+	rcd->subctxt_rcvegrbuf = vmalloc(rcd->rcvegrbuf_chunks *
+					rcd->rcvegrbuf_size *
+					num_subctxts);
 	if (!rcd->subctxt_rcvegrbuf) {
 		ret = -ENOMEM;
 		goto bail_rhdr;
@@ -1341,6 +1350,11 @@ static int init_subctxts(struct qib_devd
 	rcd->active_slaves = 1;
 	rcd->redirect_seq_cnt = 1;
 	set_bit(QIB_CTXT_MASTER_UNINIT, &rcd->flag);
+	memset(rcd->subctxt_uregbase, 0, PAGE_SIZE * num_subctxts);
+	memset(rcd->subctxt_rcvhdr_base, 0, size);
+	memset(rcd->subctxt_rcvegrbuf, 0, rcd->rcvegrbuf_chunks *
+					  rcd->rcvegrbuf_size *
+					  num_subctxts);
 	goto bail;
 
 bail_rhdr:
@@ -2341,11 +2355,11 @@ bail:
 	return ret;
 }
 
-static ssize_t qib_aio_write(struct kiocb *iocb, const struct iovec *iov,
-			     unsigned long dim, loff_t off)
+static ssize_t qib_writev(struct file *filp, const struct iovec *iov,
+			  unsigned long dim, loff_t *off)
 {
-	struct qib_filedata *fp = iocb->ki_filp->private_data;
-	struct qib_ctxtdata *rcd = ctxt_fp(iocb->ki_filp);
+	struct qib_filedata *fp = filp->private_data;
+	struct qib_ctxtdata *rcd = ctxt_fp(filp);
 	struct qib_user_sdma_queue *pq = fp->pq;
 
 	if (!dim || !pq)
@@ -2359,11 +2373,11 @@ static dev_t qib_dev;
 
 int qib_cdev_init(int minor, const char *name,
 		  const struct file_operations *fops,
-		  struct cdev **cdevp, struct device **devp)
+		  struct cdev **cdevp, struct class_device **class_devp)
 {
 	const dev_t dev = MKDEV(MAJOR(qib_dev), minor);
 	struct cdev *cdev;
-	struct device *device = NULL;
+	struct class_device *class_dev = NULL;
 	int ret;
 
 	cdev = cdev_alloc();
@@ -2387,11 +2401,12 @@ int qib_cdev_init(int minor, const char 
 		goto err_cdev;
 	}
 
-	device = device_create(qib_class, NULL, dev, NULL, name);
-	if (!IS_ERR(device))
+	class_dev = class_device_create(qib_class, NULL, dev, NULL,
+					(char *)name);
+	if (!IS_ERR(class_dev))
 		goto done;
-	ret = PTR_ERR(device);
-	device = NULL;
+	ret = PTR_ERR(class_dev);
+	class_dev = NULL;
 	printk(KERN_ERR QIB_DRV_NAME ": Could not create "
 	       "device for minor %d, %s (err %d)\n",
 	       minor, name, -ret);
@@ -2400,17 +2415,17 @@ err_cdev:
 	cdev = NULL;
 done:
 	*cdevp = cdev;
-	*devp = device;
+	*class_devp = class_dev;
 	return ret;
 }
 
-void qib_cdev_cleanup(struct cdev **cdevp, struct device **devp)
+void qib_cdev_cleanup(struct cdev **cdevp, struct class_device **class_devp)
 {
-	struct device *device = *devp;
+	struct class_device *class_dev = *class_devp;
 
-	if (device) {
-		device_unregister(device);
-		*devp = NULL;
+	if (class_dev) {
+		class_device_unregister(class_dev);
+		*class_devp = NULL;
 	}
 
 	if (*cdevp) {
@@ -2420,7 +2435,7 @@ void qib_cdev_cleanup(struct cdev **cdev
 }
 
 static struct cdev *wildcard_cdev;
-static struct device *wildcard_device;
+static struct class_device *wildcard_class_dev;
 
 int __init qib_dev_init(void)
 {
@@ -2460,9 +2475,9 @@ static atomic_t user_count = ATOMIC_INIT
 static void qib_user_remove(struct qib_devdata *dd)
 {
 	if (atomic_dec_return(&user_count) == 0)
-		qib_cdev_cleanup(&wildcard_cdev, &wildcard_device);
+		qib_cdev_cleanup(&wildcard_cdev, &wildcard_class_dev);
 
-	qib_cdev_cleanup(&dd->user_cdev, &dd->user_device);
+	qib_cdev_cleanup(&dd->user_cdev, &dd->user_class_dev);
 }
 
 static int qib_user_add(struct qib_devdata *dd)
@@ -2472,14 +2487,14 @@ static int qib_user_add(struct qib_devda
 
 	if (atomic_inc_return(&user_count) == 1) {
 		ret = qib_cdev_init(0, "ipath", &qib_file_ops,
-				    &wildcard_cdev, &wildcard_device);
+				    &wildcard_cdev, &wildcard_class_dev);
 		if (ret)
 			goto done;
 	}
 
 	snprintf(name, sizeof(name), "ipath%d", dd->unit);
 	ret = qib_cdev_init(dd->unit + 1, name, &qib_file_ops,
-			    &dd->user_cdev, &dd->user_device);
+			    &dd->user_cdev, &dd->user_class_dev);
 	if (ret)
 		qib_user_remove(dd);
 done:
diff -up a/drivers/infiniband/hw/qib/qib.h b/drivers/infiniband/hw/qib/qib.h
--- a/drivers/infiniband/hw/qib/qib.h	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib.h	2010-04-20 15:58:32.000000000 -0700
@@ -660,8 +660,8 @@ struct qib_devdata {
 	struct pci_dev *pcidev;
 	struct cdev *user_cdev;
 	struct cdev *diag_cdev;
-	struct device *user_device;
-	struct device *diag_device;
+	struct class_device *user_class_dev;
+	struct class_device *diag_class_dev;
 
 	/* mem-mapped pointer to base of chip regs */
 	u64 __iomem *kregbase;
@@ -1054,8 +1054,8 @@ int qib_count_active_units(void);
 
 int qib_cdev_init(int minor, const char *name,
 		  const struct file_operations *fops,
-		  struct cdev **cdevp, struct device **devp);
-void qib_cdev_cleanup(struct cdev **cdevp, struct device **devp);
+		  struct cdev **cdevp, struct class_device **class_devp);
+void qib_cdev_cleanup(struct cdev **cdevp, struct class_device **class_devp);
 int qib_dev_init(void);
 void qib_dev_cleanup(void);
 
diff -up a/drivers/infiniband/hw/qib/qib_iba7322.c b/drivers/infiniband/hw/qib/qib_iba7322.c
--- a/drivers/infiniband/hw/qib/qib_iba7322.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_iba7322.c	2010-04-20 15:58:32.000000000 -0700
@@ -1383,16 +1383,16 @@ static void flush_fifo(struct qib_pportd
 	u64 pbc;
 	const unsigned hdrwords = 7;
 	static struct qib_ib_header ibhdr = {
-		.lrh[0] = cpu_to_be16(0xF000 | QIB_LRH_BTH),
+		.lrh[0] = __constant_cpu_to_be16(0xF000 | QIB_LRH_BTH),
 		.lrh[1] = IB_LID_PERMISSIVE,
-		.lrh[2] = cpu_to_be16(hdrwords + SIZE_OF_CRC),
+		.lrh[2] = __constant_cpu_to_be16(hdrwords + SIZE_OF_CRC),
 		.lrh[3] = IB_LID_PERMISSIVE,
-		.u.oth.bth[0] = cpu_to_be32(
+		.u.oth.bth[0] = __constant_cpu_to_be32(
 			(IB_OPCODE_UD_SEND_ONLY << 24) | QIB_DEFAULT_P_KEY),
-		.u.oth.bth[1] = cpu_to_be32(0),
-		.u.oth.bth[2] = cpu_to_be32(0),
-		.u.oth.u.ud.deth[0] = cpu_to_be32(0),
-		.u.oth.u.ud.deth[1] = cpu_to_be32(0),
+		.u.oth.bth[1] = __constant_cpu_to_be32(0),
+		.u.oth.bth[2] = __constant_cpu_to_be32(0),
+		.u.oth.u.ud.deth[0] = __constant_cpu_to_be32(0),
+		.u.oth.u.ud.deth[1] = __constant_cpu_to_be32(0),
 	};
 
 	/*
@@ -5455,7 +5455,7 @@ static void try_7322_ipg(struct qib_ppor
 		struct ib_ah *ah;
 
 		memset(&attr, 0, sizeof attr);
-		attr.dlid = be16_to_cpu(IB_LID_PERMISSIVE);
+		attr.dlid = __constant_be16_to_cpu(IB_LID_PERMISSIVE);
 		attr.port_num = ppd->port;
 		ah = ib_create_ah(ibp->qp0->ibqp.pd, &attr);
 		if (IS_ERR(ah))
diff -up a/drivers/infiniband/hw/qib/qib_init.c b/drivers/infiniband/hw/qib/qib_init.c
--- a/drivers/infiniband/hw/qib/qib_init.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_init.c	2010-04-20 15:58:32.000000000 -0700
@@ -1422,9 +1422,10 @@ int qib_create_rcvhdrq(struct qib_devdat
 		}
 
 		if (rcd->ctxt >= dd->first_user_ctxt) {
-			rcd->user_event_mask = vmalloc_user(PAGE_SIZE);
+			rcd->user_event_mask = vmalloc(PAGE_SIZE);
 			if (!rcd->user_event_mask)
 				goto bail_free_hdrq;
+			memset(rcd->user_event_mask, 0, PAGE_SIZE);
 		}
 
 		if (!(dd->flags & QIB_NODMA_RTAIL)) {
diff -up a/drivers/infiniband/hw/qib/qib_mad.c b/drivers/infiniband/hw/qib/qib_mad.c
--- a/drivers/infiniband/hw/qib/qib_mad.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_mad.c	2010-04-20 15:58:32.000000000 -0700
@@ -88,7 +88,7 @@ static void qib_send_trap(struct qib_ibp
 
 	spin_lock_irqsave(&ibp->lock, flags);
 	if (!ibp->sm_ah) {
-		if (ibp->sm_lid != be16_to_cpu(IB_LID_PERMISSIVE)) {
+		if (ibp->sm_lid != __constant_be16_to_cpu(IB_LID_PERMISSIVE)) {
 			struct ib_ah *ah;
 			struct ib_ah_attr attr;
 
@@ -1379,7 +1379,7 @@ static int pma_get_portsamplesresult_ext
 		status = dd->f_portcntr(ppd, QIBPORTCNTR_PSSTAT);
 		p->sample_status = cpu_to_be16(status);
 		/* 64 bits */
-		p->extended_width = cpu_to_be32(0x80000000);
+		p->extended_width = __constant_cpu_to_be32(0x80000000);
 		if (status == IB_PMA_SAMPLE_STATUS_DONE) {
 			cache_hw_sample_counters(ppd);
 			ppd->cong_stats.counter =
@@ -1436,7 +1436,7 @@ static int pma_get_portcounters(struct i
 		pmp->status |= IB_SMP_INVALID_FIELD;
 
 	if (cntrs.symbol_error_counter > 0xFFFFUL)
-		p->symbol_error_counter = cpu_to_be16(0xFFFF);
+		p->symbol_error_counter = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->symbol_error_counter =
 			cpu_to_be16((u16)cntrs.symbol_error_counter);
@@ -1450,17 +1450,17 @@ static int pma_get_portcounters(struct i
 	else
 		p->link_downed_counter = (u8)cntrs.link_downed_counter;
 	if (cntrs.port_rcv_errors > 0xFFFFUL)
-		p->port_rcv_errors = cpu_to_be16(0xFFFF);
+		p->port_rcv_errors = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_rcv_errors =
 			cpu_to_be16((u16) cntrs.port_rcv_errors);
 	if (cntrs.port_rcv_remphys_errors > 0xFFFFUL)
-		p->port_rcv_remphys_errors = cpu_to_be16(0xFFFF);
+		p->port_rcv_remphys_errors = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_rcv_remphys_errors =
 			cpu_to_be16((u16)cntrs.port_rcv_remphys_errors);
 	if (cntrs.port_xmit_discards > 0xFFFFUL)
-		p->port_xmit_discards = cpu_to_be16(0xFFFF);
+		p->port_xmit_discards = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_xmit_discards =
 			cpu_to_be16((u16)cntrs.port_xmit_discards);
@@ -1471,24 +1471,24 @@ static int pma_get_portcounters(struct i
 	p->lli_ebor_errors = (cntrs.local_link_integrity_errors << 4) |
 		cntrs.excessive_buffer_overrun_errors;
 	if (cntrs.vl15_dropped > 0xFFFFUL)
-		p->vl15_dropped = cpu_to_be16(0xFFFF);
+		p->vl15_dropped = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->vl15_dropped = cpu_to_be16((u16)cntrs.vl15_dropped);
 	if (cntrs.port_xmit_data > 0xFFFFFFFFUL)
-		p->port_xmit_data = cpu_to_be32(0xFFFFFFFF);
+		p->port_xmit_data = __constant_cpu_to_be32(0xFFFFFFFF);
 	else
 		p->port_xmit_data = cpu_to_be32((u32)cntrs.port_xmit_data);
 	if (cntrs.port_rcv_data > 0xFFFFFFFFUL)
-		p->port_rcv_data = cpu_to_be32(0xFFFFFFFF);
+		p->port_rcv_data = __constant_cpu_to_be32(0xFFFFFFFF);
 	else
 		p->port_rcv_data = cpu_to_be32((u32)cntrs.port_rcv_data);
 	if (cntrs.port_xmit_packets > 0xFFFFFFFFUL)
-		p->port_xmit_packets = cpu_to_be32(0xFFFFFFFF);
+		p->port_xmit_packets = __constant_cpu_to_be32(0xFFFFFFFF);
 	else
 		p->port_xmit_packets =
 			cpu_to_be32((u32)cntrs.port_xmit_packets);
 	if (cntrs.port_rcv_packets > 0xFFFFFFFFUL)
-		p->port_rcv_packets = cpu_to_be32(0xFFFFFFFF);
+		p->port_rcv_packets = __constant_cpu_to_be32(0xFFFFFFFF);
 	else
 		p->port_rcv_packets =
 			cpu_to_be32((u32) cntrs.port_rcv_packets);
@@ -1556,7 +1556,7 @@ static int pma_get_portcounters_cong(str
 		cpu_to_be16((QIB_XMIT_RATE_PICO << 13) |
 			    (dd->psxmitwait_check_rate &
 			     ~(QIB_XMIT_RATE_PICO << 13)));
-	p->port_adr_events = cpu_to_be64(0);
+	p->port_adr_events = __constant_cpu_to_be64(0);
 	p->port_xmit_wait = cpu_to_be64(xmit_wait_counter);
 	p->port_xmit_data = cpu_to_be64(cntrs.port_xmit_data);
 	p->port_rcv_data = cpu_to_be64(cntrs.port_rcv_data);
@@ -1565,7 +1565,7 @@ static int pma_get_portcounters_cong(str
 	p->port_rcv_packets =
 		cpu_to_be64(cntrs.port_rcv_packets);
 	if (cntrs.symbol_error_counter > 0xFFFFUL)
-		p->symbol_error_counter = cpu_to_be16(0xFFFF);
+		p->symbol_error_counter = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->symbol_error_counter =
 			cpu_to_be16(
@@ -1581,18 +1581,18 @@ static int pma_get_portcounters_cong(str
 		p->link_downed_counter =
 			(u8)cntrs.link_downed_counter;
 	if (cntrs.port_rcv_errors > 0xFFFFUL)
-		p->port_rcv_errors = cpu_to_be16(0xFFFF);
+		p->port_rcv_errors = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_rcv_errors =
 			cpu_to_be16((u16) cntrs.port_rcv_errors);
 	if (cntrs.port_rcv_remphys_errors > 0xFFFFUL)
-		p->port_rcv_remphys_errors = cpu_to_be16(0xFFFF);
+		p->port_rcv_remphys_errors = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_rcv_remphys_errors =
 			cpu_to_be16(
 				(u16)cntrs.port_rcv_remphys_errors);
 	if (cntrs.port_xmit_discards > 0xFFFFUL)
-		p->port_xmit_discards = cpu_to_be16(0xFFFF);
+		p->port_xmit_discards = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_xmit_discards =
 			cpu_to_be16((u16)cntrs.port_xmit_discards);
@@ -1603,7 +1603,7 @@ static int pma_get_portcounters_cong(str
 	p->lli_ebor_errors = (cntrs.local_link_integrity_errors << 4) |
 		cntrs.excessive_buffer_overrun_errors;
 	if (cntrs.vl15_dropped > 0xFFFFUL)
-		p->vl15_dropped = cpu_to_be16(0xFFFF);
+		p->vl15_dropped = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->vl15_dropped = cpu_to_be16((u16)cntrs.vl15_dropped);
 
diff -up a/drivers/infiniband/hw/qib/qib_mad.h b/drivers/infiniband/hw/qib/qib_mad.h
--- a/drivers/infiniband/hw/qib/qib_mad.h	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_mad.h	2010-04-20 15:58:32.000000000 -0700
@@ -32,10 +32,10 @@
  * SOFTWARE.
  */
 
-#define IB_SMP_UNSUP_VERSION    cpu_to_be16(0x0004)
-#define IB_SMP_UNSUP_METHOD     cpu_to_be16(0x0008)
-#define IB_SMP_UNSUP_METH_ATTR  cpu_to_be16(0x000C)
-#define IB_SMP_INVALID_FIELD    cpu_to_be16(0x001C)
+#define IB_SMP_UNSUP_VERSION    __constant_cpu_to_be16(0x0004)
+#define IB_SMP_UNSUP_METHOD     __constant_cpu_to_be16(0x0008)
+#define IB_SMP_UNSUP_METH_ATTR  __constant_cpu_to_be16(0x000C)
+#define IB_SMP_INVALID_FIELD    __constant_cpu_to_be16(0x001C)
 
 struct ib_node_info {
 	u8 base_version;
@@ -128,22 +128,22 @@ struct ib_mad_notice_attr {
 /*
  * Generic trap/notice producers
  */
-#define IB_NOTICE_PROD_CA		cpu_to_be16(1)
-#define IB_NOTICE_PROD_SWITCH		cpu_to_be16(2)
-#define IB_NOTICE_PROD_ROUTER		cpu_to_be16(3)
-#define IB_NOTICE_PROD_CLASS_MGR	cpu_to_be16(4)
+#define IB_NOTICE_PROD_CA		__constant_cpu_to_be16(1)
+#define IB_NOTICE_PROD_SWITCH		__constant_cpu_to_be16(2)
+#define IB_NOTICE_PROD_ROUTER		__constant_cpu_to_be16(3)
+#define IB_NOTICE_PROD_CLASS_MGR	__constant_cpu_to_be16(4)
 
 /*
  * Generic trap/notice numbers
  */
-#define IB_NOTICE_TRAP_LLI_THRESH	cpu_to_be16(129)
-#define IB_NOTICE_TRAP_EBO_THRESH	cpu_to_be16(130)
-#define IB_NOTICE_TRAP_FLOW_UPDATE	cpu_to_be16(131)
-#define IB_NOTICE_TRAP_CAP_MASK_CHG	cpu_to_be16(144)
-#define IB_NOTICE_TRAP_SYS_GUID_CHG	cpu_to_be16(145)
-#define IB_NOTICE_TRAP_BAD_MKEY		cpu_to_be16(256)
-#define IB_NOTICE_TRAP_BAD_PKEY		cpu_to_be16(257)
-#define IB_NOTICE_TRAP_BAD_QKEY		cpu_to_be16(258)
+#define IB_NOTICE_TRAP_LLI_THRESH	__constant_cpu_to_be16(129)
+#define IB_NOTICE_TRAP_EBO_THRESH	__constant_cpu_to_be16(130)
+#define IB_NOTICE_TRAP_FLOW_UPDATE	__constant_cpu_to_be16(131)
+#define IB_NOTICE_TRAP_CAP_MASK_CHG	__constant_cpu_to_be16(144)
+#define IB_NOTICE_TRAP_SYS_GUID_CHG	__constant_cpu_to_be16(145)
+#define IB_NOTICE_TRAP_BAD_MKEY		__constant_cpu_to_be16(256)
+#define IB_NOTICE_TRAP_BAD_PKEY		__constant_cpu_to_be16(257)
+#define IB_NOTICE_TRAP_BAD_QKEY		__constant_cpu_to_be16(258)
 
 /*
  * Repress trap/notice flags
@@ -183,17 +183,17 @@ struct ib_vl_weight_elem {
 /*
  * PMA class portinfo capability mask bits
  */
-#define IB_PMA_CLASS_CAP_ALLPORTSELECT  cpu_to_be16(1 << 8)
-#define IB_PMA_CLASS_CAP_EXT_WIDTH      cpu_to_be16(1 << 9)
-#define IB_PMA_CLASS_CAP_XMIT_WAIT      cpu_to_be16(1 << 12)
-
-#define IB_PMA_CLASS_PORT_INFO          cpu_to_be16(0x0001)
-#define IB_PMA_PORT_SAMPLES_CONTROL     cpu_to_be16(0x0010)
-#define IB_PMA_PORT_SAMPLES_RESULT      cpu_to_be16(0x0011)
-#define IB_PMA_PORT_COUNTERS            cpu_to_be16(0x0012)
-#define IB_PMA_PORT_COUNTERS_EXT        cpu_to_be16(0x001D)
-#define IB_PMA_PORT_SAMPLES_RESULT_EXT  cpu_to_be16(0x001E)
-#define IB_PMA_PORT_COUNTERS_CONG       cpu_to_be16(0xFF00)
+#define IB_PMA_CLASS_CAP_ALLPORTSELECT  __constant_cpu_to_be16(1 << 8)
+#define IB_PMA_CLASS_CAP_EXT_WIDTH      __constant_cpu_to_be16(1 << 9)
+#define IB_PMA_CLASS_CAP_XMIT_WAIT      __constant_cpu_to_be16(1 << 12)
+
+#define IB_PMA_CLASS_PORT_INFO          __constant_cpu_to_be16(0x0001)
+#define IB_PMA_PORT_SAMPLES_CONTROL     __constant_cpu_to_be16(0x0010)
+#define IB_PMA_PORT_SAMPLES_RESULT      __constant_cpu_to_be16(0x0011)
+#define IB_PMA_PORT_COUNTERS            __constant_cpu_to_be16(0x0012)
+#define IB_PMA_PORT_COUNTERS_EXT        __constant_cpu_to_be16(0x001D)
+#define IB_PMA_PORT_SAMPLES_RESULT_EXT  __constant_cpu_to_be16(0x001E)
+#define IB_PMA_PORT_COUNTERS_CONG       __constant_cpu_to_be16(0xFF00)
 
 struct ib_perf {
 	u8 base_version;
@@ -316,19 +316,19 @@ struct ib_pma_portcounters_cong {
 /* number of 4nsec cycles equaling 2secs */
 #define QIB_CONG_TIMER_PSINTERVAL               0x1DCD64EC
 
-#define IB_PMA_SEL_SYMBOL_ERROR                 cpu_to_be16(0x0001)
-#define IB_PMA_SEL_LINK_ERROR_RECOVERY          cpu_to_be16(0x0002)
-#define IB_PMA_SEL_LINK_DOWNED                  cpu_to_be16(0x0004)
-#define IB_PMA_SEL_PORT_RCV_ERRORS              cpu_to_be16(0x0008)
-#define IB_PMA_SEL_PORT_RCV_REMPHYS_ERRORS      cpu_to_be16(0x0010)
-#define IB_PMA_SEL_PORT_XMIT_DISCARDS           cpu_to_be16(0x0040)
-#define IB_PMA_SEL_LOCAL_LINK_INTEGRITY_ERRORS  cpu_to_be16(0x0200)
-#define IB_PMA_SEL_EXCESSIVE_BUFFER_OVERRUNS    cpu_to_be16(0x0400)
-#define IB_PMA_SEL_PORT_VL15_DROPPED            cpu_to_be16(0x0800)
-#define IB_PMA_SEL_PORT_XMIT_DATA               cpu_to_be16(0x1000)
-#define IB_PMA_SEL_PORT_RCV_DATA                cpu_to_be16(0x2000)
-#define IB_PMA_SEL_PORT_XMIT_PACKETS            cpu_to_be16(0x4000)
-#define IB_PMA_SEL_PORT_RCV_PACKETS             cpu_to_be16(0x8000)
+#define IB_PMA_SEL_SYMBOL_ERROR                 __constant_cpu_to_be16(0x0001)
+#define IB_PMA_SEL_LINK_ERROR_RECOVERY          __constant_cpu_to_be16(0x0002)
+#define IB_PMA_SEL_LINK_DOWNED                  __constant_cpu_to_be16(0x0004)
+#define IB_PMA_SEL_PORT_RCV_ERRORS              __constant_cpu_to_be16(0x0008)
+#define IB_PMA_SEL_PORT_RCV_REMPHYS_ERRORS      __constant_cpu_to_be16(0x0010)
+#define IB_PMA_SEL_PORT_XMIT_DISCARDS           __constant_cpu_to_be16(0x0040)
+#define IB_PMA_SEL_LOCAL_LINK_INTEGRITY_ERRORS  __constant_cpu_to_be16(0x0200)
+#define IB_PMA_SEL_EXCESSIVE_BUFFER_OVERRUNS    __constant_cpu_to_be16(0x0400)
+#define IB_PMA_SEL_PORT_VL15_DROPPED            __constant_cpu_to_be16(0x0800)
+#define IB_PMA_SEL_PORT_XMIT_DATA               __constant_cpu_to_be16(0x1000)
+#define IB_PMA_SEL_PORT_RCV_DATA                __constant_cpu_to_be16(0x2000)
+#define IB_PMA_SEL_PORT_XMIT_PACKETS            __constant_cpu_to_be16(0x4000)
+#define IB_PMA_SEL_PORT_RCV_PACKETS             __constant_cpu_to_be16(0x8000)
 
 #define IB_PMA_SEL_CONG_ALL                     0x01
 #define IB_PMA_SEL_CONG_PORT_DATA               0x02
@@ -350,14 +350,14 @@ struct ib_pma_portcounters_ext {
 	__be64 port_multicast_rcv_packets;
 } __attribute__ ((packed));
 
-#define IB_PMA_SELX_PORT_XMIT_DATA              cpu_to_be16(0x0001)
-#define IB_PMA_SELX_PORT_RCV_DATA               cpu_to_be16(0x0002)
-#define IB_PMA_SELX_PORT_XMIT_PACKETS           cpu_to_be16(0x0004)
-#define IB_PMA_SELX_PORT_RCV_PACKETS            cpu_to_be16(0x0008)
-#define IB_PMA_SELX_PORT_UNI_XMIT_PACKETS       cpu_to_be16(0x0010)
-#define IB_PMA_SELX_PORT_UNI_RCV_PACKETS        cpu_to_be16(0x0020)
-#define IB_PMA_SELX_PORT_MULTI_XMIT_PACKETS     cpu_to_be16(0x0040)
-#define IB_PMA_SELX_PORT_MULTI_RCV_PACKETS      cpu_to_be16(0x0080)
+#define IB_PMA_SELX_PORT_XMIT_DATA              __constant_cpu_to_be16(0x0001)
+#define IB_PMA_SELX_PORT_RCV_DATA               __constant_cpu_to_be16(0x0002)
+#define IB_PMA_SELX_PORT_XMIT_PACKETS           __constant_cpu_to_be16(0x0004)
+#define IB_PMA_SELX_PORT_RCV_PACKETS            __constant_cpu_to_be16(0x0008)
+#define IB_PMA_SELX_PORT_UNI_XMIT_PACKETS       __constant_cpu_to_be16(0x0010)
+#define IB_PMA_SELX_PORT_UNI_RCV_PACKETS        __constant_cpu_to_be16(0x0020)
+#define IB_PMA_SELX_PORT_MULTI_XMIT_PACKETS     __constant_cpu_to_be16(0x0040)
+#define IB_PMA_SELX_PORT_MULTI_RCV_PACKETS      __constant_cpu_to_be16(0x0080)
 
 /*
  * The PortSamplesControl.CounterMasks field is an array of 3 bit fields
@@ -366,9 +366,9 @@ struct ib_pma_portcounters_ext {
  */
 #define COUNTER_MASK(q, n) (q << ((9 - n) * 3))
 #define COUNTER_MASK0_9 \
-	cpu_to_be32(COUNTER_MASK(1, 0) | \
-		    COUNTER_MASK(1, 1) | \
-		    COUNTER_MASK(1, 2) | \
-		    COUNTER_MASK(1, 3) | \
-		    COUNTER_MASK(1, 4))
+	__constant_cpu_to_be32(COUNTER_MASK(1, 0) | \
+			       COUNTER_MASK(1, 1) | \
+			       COUNTER_MASK(1, 2) | \
+			       COUNTER_MASK(1, 3) | \
+			       COUNTER_MASK(1, 4))
 
diff -up a/drivers/infiniband/hw/qib/qib_mmap.c b/drivers/infiniband/hw/qib/qib_mmap.c
--- a/drivers/infiniband/hw/qib/qib_mmap.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_mmap.c	2010-04-20 15:58:32.000000000 -0700
@@ -74,9 +74,40 @@ static void qib_vma_close(struct vm_area
 	kref_put(&ip->ref, qib_release_mmap_info);
 }
 
+/*
+ * qib_vma_nopage - handle a VMA page fault.
+ */
+static struct page *qib_vma_nopage(struct vm_area_struct *vma,
+				     unsigned long address, int *type)
+{
+	struct qib_mmap_info *ip = vma->vm_private_data;
+	unsigned long offset = address - vma->vm_start;
+	struct page *page = NOPAGE_SIGBUS;
+	void *pageptr;
+
+	if (offset >= ip->size)
+		goto out; /* out of range */
+
+	/*
+	 * Convert the vmalloc address into a struct page.
+	 */
+	pageptr = (void *)(offset + ip->obj);
+	page = vmalloc_to_page(pageptr);
+	if (!page)
+		goto out;
+
+	/* Increment the reference count. */
+	get_page(page);
+	if (type)
+		*type = VM_FAULT_MINOR;
+out:
+	return page;
+}
+
 static struct vm_operations_struct qib_vm_ops = {
 	.open =     qib_vma_open,
 	.close =    qib_vma_close,
+	.nopage =   qib_vma_nopage,
 };
 
 /**
@@ -111,10 +142,10 @@ int qib_mmap(struct ib_ucontext *context
 		list_del_init(&ip->pending_mmaps);
 		spin_unlock_irq(&dev->pending_lock);
 
-		ret = remap_vmalloc_range(vma, ip->obj, 0);
-		if (ret)
-			goto done;
+		ret = 0;
+
 		vma->vm_ops = &qib_vm_ops;
+		vma->vm_flags |= VM_RESERVED | VM_DONTEXPAND;
 		vma->vm_private_data = ip;
 		qib_vma_open(vma);
 		goto done;
diff -up a/drivers/infiniband/hw/qib/qib_qp.c b/drivers/infiniband/hw/qib/qib_qp.c
--- a/drivers/infiniband/hw/qib/qib_qp.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_qp.c	2010-04-20 16:39:27.000000000 -0700
@@ -37,6 +37,9 @@
 
 #include "qib.h"
 
+/* Undo OFED backport changes so we get the real cancel_delayed_work() */
+#undef cancel_delayed_work
+
 #define BITS_PER_PAGE           (PAGE_SIZE*BITS_PER_BYTE)
 #define BITS_PER_PAGE_MASK      (BITS_PER_PAGE-1)
 
@@ -675,7 +678,8 @@ int qib_modify_qp(struct ib_qp *ibqp, st
 			qp->s_flags &= ~(QIB_S_TIMER | QIB_S_ANY_WAIT);
 			spin_unlock_irq(&qp->s_lock);
 			/* Stop the sending work queue and retry timer */
-			cancel_work_sync(&qp->s_work);
+			cancel_delayed_work(&qp->s_work);
+			flush_workqueue(qib_wq);
 			del_timer_sync(&qp->s_timer);
 			wait_event(qp->wait_dma, !atomic_read(&qp->s_dma_busy));
 			if (qp->s_tx) {
@@ -1011,12 +1015,14 @@ struct ib_qp *qib_create_qp(struct ib_pd
 			qp->r_rq.max_sge = init_attr->cap.max_recv_sge;
 			sz = (sizeof(struct ib_sge) * qp->r_rq.max_sge) +
 				sizeof(struct qib_rwqe);
-			qp->r_rq.wq = vmalloc_user(sizeof(struct qib_rwq) +
-						   qp->r_rq.size * sz);
+			qp->r_rq.wq = vmalloc(sizeof(struct qib_rwq) +
+					      qp->r_rq.size * sz);
 			if (!qp->r_rq.wq) {
 				ret = ERR_PTR(-ENOMEM);
 				goto bail_qp;
 			}
+			memset(qp->r_rq.wq, 0,
+			       sizeof(struct qib_rwq) + qp->r_rq.size * sz);
 		}
 
 		/*
@@ -1052,6 +1058,7 @@ struct ib_qp *qib_create_qp(struct ib_pd
 		qp->ibqp.qp_num = err;
 		qp->port_num = init_attr->port_num;
 		qp->processor_id = smp_processor_id();
+		qp->send_proc_id = smp_processor_id();
 		qib_reset_qp(qp, init_attr->qp_type);
 		break;
 
@@ -1154,7 +1161,8 @@ int qib_destroy_qp(struct ib_qp *ibqp)
 		spin_unlock(&dev->pending_lock);
 		qp->s_flags &= ~(QIB_S_TIMER | QIB_S_ANY_WAIT);
 		spin_unlock_irq(&qp->s_lock);
-		cancel_work_sync(&qp->s_work);
+		cancel_delayed_work(&qp->s_work);
+		flush_workqueue(qib_wq);
 		del_timer_sync(&qp->s_timer);
 		wait_event(qp->wait_dma, !atomic_read(&qp->s_dma_busy));
 		if (qp->s_tx) {
diff -up a/drivers/infiniband/hw/qib/qib_rc.c b/drivers/infiniband/hw/qib/qib_rc.c
--- a/drivers/infiniband/hw/qib/qib_rc.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_rc.c	2010-04-20 16:39:32.000000000 -0700
@@ -113,6 +113,7 @@ static int qib_make_rc_ack(struct qib_ib
 	case OP(ACKNOWLEDGE):
 		/* Check for no next entry in the queue. */
 		if (qp->r_head_ack_queue == qp->s_tail_ack_queue) {
+			qp->send_proc_id = qp->processor_id;
 			if (qp->s_flags & QIB_S_ACK_PENDING)
 				goto normal;
 			goto bail;
@@ -2040,7 +2041,7 @@ send_last:
 		/* Signal completion event if the solicited bit is set. */
 		qib_cq_enter(to_icq(qp->ibqp.recv_cq), &wc,
 			     (ohdr->bth[0] &
-			      cpu_to_be32(IB_BTH_SOLICITED)) != 0);
+			      __constant_cpu_to_be32(IB_BTH_SOLICITED)) != 0);
 		break;
 
 	case OP(RDMA_WRITE_FIRST):
@@ -2147,7 +2148,8 @@ send_last:
 		qp->r_nak_state = 0;
 		qp->r_head_ack_queue = next;
 
-		/* Schedule the send tasklet. */
+		/* Schedule the send tasklet on the current processor. */
+		qp->send_proc_id = smp_processor_id();
 		qp->s_flags |= QIB_S_RESP_PENDING;
 		qib_schedule_send(qp);
 
diff -up a/drivers/infiniband/hw/qib/qib_sdma.c b/drivers/infiniband/hw/qib/qib_sdma.c
--- a/drivers/infiniband/hw/qib/qib_sdma.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_sdma.c	2010-04-20 15:58:32.000000000 -0700
@@ -591,7 +591,7 @@ retry:
 		dw = (len + 3) >> 2;
 		addr = dma_map_single(&ppd->dd->pcidev->dev, sge->vaddr,
 				      dw << 2, DMA_TO_DEVICE);
-		if (dma_mapping_error(&ppd->dd->pcidev->dev, addr))
+		if (dma_mapping_error(addr))
 			goto unmap;
 		sdmadesc[0] = 0;
 		make_sdma_desc(ppd, sdmadesc, (u64) addr, dw, dwoffset);
@@ -633,11 +633,11 @@ retry:
 	if (!tail)
 		descqp = &ppd->sdma_descq[ppd->sdma_descq_cnt].qw[0];
 	descqp -= 2;
-	descqp[0] |= cpu_to_le64(SDMA_DESC_LAST);
+	descqp[0] |= __constant_cpu_to_le64(SDMA_DESC_LAST);
 	if (tx->txreq.flags & QIB_SDMA_TXREQ_F_HEADTOHOST)
-		descqp[0] |= cpu_to_le64(SDMA_DESC_DMA_HEAD);
+		descqp[0] |= __constant_cpu_to_le64(SDMA_DESC_DMA_HEAD);
 	if (tx->txreq.flags & QIB_SDMA_TXREQ_F_INTREQ)
-		descqp[0] |= cpu_to_le64(SDMA_DESC_INTR);
+		descqp[0] |= __constant_cpu_to_le64(SDMA_DESC_INTR);
 
 	atomic_inc(&tx->qp->s_dma_busy);
 	tx->txreq.next_descq_idx = tail;
diff -up a/drivers/infiniband/hw/qib/qib_srq.c b/drivers/infiniband/hw/qib/qib_srq.c
--- a/drivers/infiniband/hw/qib/qib_srq.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_srq.c	2010-04-20 15:58:32.000000000 -0700
@@ -127,11 +127,12 @@ struct ib_srq *qib_create_srq(struct ib_
 	srq->rq.max_sge = srq_init_attr->attr.max_sge;
 	sz = sizeof(struct ib_sge) * srq->rq.max_sge +
 		sizeof(struct qib_rwqe);
-	srq->rq.wq = vmalloc_user(sizeof(struct qib_rwq) + srq->rq.size * sz);
+	srq->rq.wq = vmalloc(sizeof(struct qib_rwq) + srq->rq.size * sz);
 	if (!srq->rq.wq) {
 		ret = ERR_PTR(-ENOMEM);
 		goto bail_srq;
 	}
+	memset(srq->rq.wq, 0, sizeof(struct qib_rwq) + srq->rq.size * sz);
 
 	/*
 	 * Return the address of the RWQ as the offset to mmap.
@@ -226,11 +227,12 @@ int qib_modify_srq(struct ib_srq *ibsrq,
 		sz = sizeof(struct qib_rwqe) +
 			srq->rq.max_sge * sizeof(struct ib_sge);
 		size = attr->max_wr + 1;
-		wq = vmalloc_user(sizeof(struct qib_rwq) + size * sz);
+		wq = vmalloc(sizeof(struct qib_rwq) + size * sz);
 		if (!wq) {
 			ret = -ENOMEM;
 			goto bail;
 		}
+		memset(wq, 0, sizeof(struct qib_rwq) + size * sz);
 
 		/* Check that we can write the offset to mmap. */
 		if (udata && udata->inlen >= sizeof(__u64)) {
diff -up a/drivers/infiniband/hw/qib/qib_sysfs.c b/drivers/infiniband/hw/qib/qib_sysfs.c
--- a/drivers/infiniband/hw/qib/qib_sysfs.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_sysfs.c	2010-04-20 15:58:32.000000000 -0700
@@ -262,18 +262,12 @@ static ssize_t qib_portattr_store(struct
 	return pattr->store(ppd, buf, len);
 }
 
-static void qib_port_release(struct kobject *kobj)
-{
-	/* nothing to do since memory is freed by qib_free_devdata() */
-}
-
 static struct sysfs_ops qib_port_ops = {
 	.show = qib_portattr_show,
 	.store = qib_portattr_store,
 };
 
 static struct kobj_type qib_port_ktype = {
-	.release = qib_port_release,
 	.sysfs_ops = &qib_port_ops,
 	.default_attrs = port_default_attributes
 };
@@ -345,7 +339,6 @@ static struct sysfs_ops qib_sl2vl_ops = 
 };
 
 static struct kobj_type qib_sl2vl_ktype = {
-	.release = qib_port_release,
 	.sysfs_ops = &qib_sl2vl_ops,
 	.default_attrs = sl2vl_default_attributes
 };
@@ -356,22 +349,20 @@ static struct kobj_type qib_sl2vl_ktype 
 
 /*
  * Start of per-unit (or driver, in some cases, but replicated
- * per unit) functions (these get a device *)
+ * per unit) functions (these get a class_device *)
  */
-static ssize_t show_rev(struct device *device, struct device_attribute *attr,
-			char *buf)
+static ssize_t show_rev(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 
 	return sprintf(buf, "%x\n", dd_from_dev(dev)->minrev);
 }
 
-static ssize_t show_hca(struct device *device, struct device_attribute *attr,
-			char *buf)
+static ssize_t show_hca(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 	int ret;
 
@@ -386,11 +377,10 @@ static const char *qp_type_str[] = {
 	"SMI", "GSI", "RC", "UC", "UD",
 };
 
-static ssize_t show_stats(struct device *device, struct device_attribute *attr,
-			  char *buf)
+static ssize_t show_stats(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 	unsigned pidx;
 	unsigned i;
@@ -487,18 +477,16 @@ static ssize_t show_stats(struct device 
 	return len;
 }
 
-static ssize_t show_version(struct device *device,
-			    struct device_attribute *attr, char *buf)
+static ssize_t show_version(struct class_device *cdev, char *buf)
 {
 	/* The string printed here is already newline-terminated. */
 	return scnprintf(buf, PAGE_SIZE, "%s", (char *)ib_qib_version);
 }
 
-static ssize_t show_boardversion(struct device *device,
-				 struct device_attribute *attr, char *buf)
+static ssize_t show_boardversion(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 
 	/* The string printed here is already newline-terminated. */
@@ -506,11 +494,10 @@ static ssize_t show_boardversion(struct 
 }
 
 
-static ssize_t show_localbus_info(struct device *device,
-				  struct device_attribute *attr, char *buf)
+static ssize_t show_localbus_info(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 
 	/* The string printed here is already newline-terminated. */
@@ -518,11 +505,10 @@ static ssize_t show_localbus_info(struct
 }
 
 
-static ssize_t show_nctxts(struct device *device,
-			   struct device_attribute *attr, char *buf)
+static ssize_t show_nctxts(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 
 	/* Return the number of user ports (contexts) available. */
@@ -530,11 +516,10 @@ static ssize_t show_nctxts(struct device
 		dd->first_user_ctxt);
 }
 
-static ssize_t show_serial(struct device *device,
-			   struct device_attribute *attr, char *buf)
+static ssize_t show_serial(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 
 	buf[sizeof dd->serial] = '\0';
@@ -543,12 +528,11 @@ static ssize_t show_serial(struct device
 	return strlen(buf);
 }
 
-static ssize_t store_chip_reset(struct device *device,
-				struct device_attribute *attr, const char *buf,
+static ssize_t store_chip_reset(struct class_device *cdev, const char *buf,
 				size_t count)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 	int ret;
 
@@ -562,11 +546,10 @@ bail:
 	return ret < 0 ? ret : count;
 }
 
-static ssize_t show_logged_errs(struct device *device,
-				struct device_attribute *attr, char *buf)
+static ssize_t show_logged_errs(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 	int idx, count;
 
@@ -587,11 +570,10 @@ static ssize_t show_logged_errs(struct d
 /*
  * Dump tempsense regs. in decimal, to ease shell-scripts.
  */
-static ssize_t show_tempsense(struct device *device,
-			      struct device_attribute *attr, char *buf)
+static ssize_t show_tempsense(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 	int ret;
 	int idx;
@@ -622,32 +604,32 @@ static ssize_t show_tempsense(struct dev
  */
 
 /* start of per-unit file structures and support code */
-static DEVICE_ATTR(hw_rev, S_IRUGO, show_rev, NULL);
-static DEVICE_ATTR(hca_type, S_IRUGO, show_hca, NULL);
-static DEVICE_ATTR(board_id, S_IRUGO, show_hca, NULL);
-static DEVICE_ATTR(stats, S_IRUGO, show_stats, NULL);
-static DEVICE_ATTR(version, S_IRUGO, show_version, NULL);
-static DEVICE_ATTR(nctxts, S_IRUGO, show_nctxts, NULL);
-static DEVICE_ATTR(serial, S_IRUGO, show_serial, NULL);
-static DEVICE_ATTR(boardversion, S_IRUGO, show_boardversion, NULL);
-static DEVICE_ATTR(logged_errors, S_IRUGO, show_logged_errs, NULL);
-static DEVICE_ATTR(tempsense, S_IRUGO, show_tempsense, NULL);
-static DEVICE_ATTR(localbus_info, S_IRUGO, show_localbus_info, NULL);
-static DEVICE_ATTR(chip_reset, S_IWUSR, NULL, store_chip_reset);
-
-static struct device_attribute *qib_attributes[] = {
-	&dev_attr_hw_rev,
-	&dev_attr_hca_type,
-	&dev_attr_board_id,
-	&dev_attr_stats,
-	&dev_attr_version,
-	&dev_attr_nctxts,
-	&dev_attr_serial,
-	&dev_attr_boardversion,
-	&dev_attr_logged_errors,
-	&dev_attr_tempsense,
-	&dev_attr_localbus_info,
-	&dev_attr_chip_reset,
+static CLASS_DEVICE_ATTR(hw_rev, S_IRUGO, show_rev, NULL);
+static CLASS_DEVICE_ATTR(hca_type, S_IRUGO, show_hca, NULL);
+static CLASS_DEVICE_ATTR(board_id, S_IRUGO, show_hca, NULL);
+static CLASS_DEVICE_ATTR(stats, S_IRUGO, show_stats, NULL);
+static CLASS_DEVICE_ATTR(version, S_IRUGO, show_version, NULL);
+static CLASS_DEVICE_ATTR(nctxts, S_IRUGO, show_nctxts, NULL);
+static CLASS_DEVICE_ATTR(serial, S_IRUGO, show_serial, NULL);
+static CLASS_DEVICE_ATTR(boardversion, S_IRUGO, show_boardversion, NULL);
+static CLASS_DEVICE_ATTR(logged_errors, S_IRUGO, show_logged_errs, NULL);
+static CLASS_DEVICE_ATTR(tempsense, S_IRUGO, show_tempsense, NULL);
+static CLASS_DEVICE_ATTR(localbus_info, S_IRUGO, show_localbus_info, NULL);
+static CLASS_DEVICE_ATTR(chip_reset, S_IWUSR, NULL, store_chip_reset);
+
+static struct class_device_attribute *qib_class_attributes[] = {
+	&class_device_attr_hw_rev,
+	&class_device_attr_hca_type,
+	&class_device_attr_board_id,
+	&class_device_attr_stats,
+	&class_device_attr_version,
+	&class_device_attr_nctxts,
+	&class_device_attr_serial,
+	&class_device_attr_boardversion,
+	&class_device_attr_logged_errors,
+	&class_device_attr_tempsense,
+	&class_device_attr_localbus_info,
+	&class_device_attr_chip_reset,
 };
 
 static int create_port_files(struct ib_device *ibdev, u8 port_num,
@@ -709,8 +691,9 @@ int qib_verbs_register_sysfs(struct qib_
 	struct ib_device *dev = &dd->verbs_dev.ibdev;
 	int i, ret;
 
-	for (i = 0; i < ARRAY_SIZE(qib_attributes); ++i)
-		if (device_create_file(&dev->dev, qib_attributes[i])) {
+	for (i = 0; i < ARRAY_SIZE(qib_class_attributes); ++i)
+		if (class_device_create_file(&dev->class_dev,
+					     qib_class_attributes[i])) {
 			ret = 1;
 			goto bail;
 		}
diff -up a/drivers/infiniband/hw/qib/qib_trace.c b/drivers/infiniband/hw/qib/qib_trace.c
--- a/drivers/infiniband/hw/qib/qib_trace.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_trace.c	2010-04-20 15:58:32.000000000 -0700
@@ -245,7 +245,7 @@ struct qib_evt_file {
 
 struct evt_trace_device {
 	struct cdev *cdev;
-	struct device *device;
+	struct class_device *class_dev;
 };
 
 static int qib_trace_set_bufsize(const char *val, struct kernel_param *kp);
@@ -1318,7 +1318,7 @@ int __init qib_trace_init(void)
 	}
 
 	ret = qib_cdev_init(QIB_TRACE_MINOR, QIB_TRACE_FILE, &qib_trace_fops,
-			    &evt_dev.cdev, &evt_dev.device);
+			    &evt_dev.cdev, &evt_dev.class_dev);
 	if (ret)
 		goto bail_buf;
 
@@ -1341,7 +1341,7 @@ bail:
 void __exit qib_trace_fini(void)
 {
 	if (qib_trace_buf) {
-		qib_cdev_cleanup(&evt_dev.cdev, &evt_dev.device);
+		qib_cdev_cleanup(&evt_dev.cdev, &evt_dev.class_dev);
 		atomic_notifier_chain_unregister(&panic_notifier_list,
 						 &qibtrace_panic_block);
 		qib_evt_buf_destroy(qib_trace_buf);
diff -up a/drivers/infiniband/hw/qib/qib_uc.c b/drivers/infiniband/hw/qib/qib_uc.c
--- a/drivers/infiniband/hw/qib/qib_uc.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_uc.c	2010-04-20 15:58:32.000000000 -0700
@@ -432,7 +432,7 @@ last_imm:
 		/* Signal completion event if the solicited bit is set. */
 		qib_cq_enter(to_icq(qp->ibqp.recv_cq), &wc,
 			     (ohdr->bth[0] &
-				cpu_to_be32(IB_BTH_SOLICITED)) != 0);
+				__constant_cpu_to_be32(IB_BTH_SOLICITED)) != 0);
 		break;
 
 	case OP(RDMA_WRITE_FIRST):
diff -up a/drivers/infiniband/hw/qib/qib_ud.c b/drivers/infiniband/hw/qib/qib_ud.c
--- a/drivers/infiniband/hw/qib/qib_ud.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_ud.c	2010-04-20 15:58:32.000000000 -0700
@@ -367,7 +367,7 @@ int qib_make_ud_req(struct qib_qp *qp)
 	 */
 	ohdr->bth[1] = ah_attr->dlid >= QIB_MULTICAST_LID_BASE &&
 		ah_attr->dlid != QIB_PERMISSIVE_LID ?
-		cpu_to_be32(QIB_MULTICAST_QPN) :
+		__constant_cpu_to_be32(QIB_MULTICAST_QPN) :
 		cpu_to_be32(wqe->wr.wr.ud.remote_qpn);
 	ohdr->bth[2] = cpu_to_be32(qp->s_next_psn++ & QIB_PSN_MASK);
 	/*
@@ -600,6 +600,6 @@ void qib_ud_rcv(struct qib_ibport *ibp, 
 	/* Signal completion event if the solicited bit is set. */
 	qib_cq_enter(to_icq(qp->ibqp.recv_cq), &wc,
 		     (ohdr->bth[0] &
-			cpu_to_be32(IB_BTH_SOLICITED)) != 0);
+			__constant_cpu_to_be32(IB_BTH_SOLICITED)) != 0);
 bail:;
 }
diff -up a/drivers/infiniband/hw/qib/qib_user_sdma.c b/drivers/infiniband/hw/qib/qib_user_sdma.c
--- a/drivers/infiniband/hw/qib/qib_user_sdma.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_user_sdma.c	2010-04-20 15:58:32.000000000 -0700
@@ -207,7 +207,7 @@ static int qib_user_sdma_coalesce(const 
 
 	dma_addr = dma_map_page(&dd->pcidev->dev, page, 0, len,
 				DMA_TO_DEVICE);
-	if (dma_mapping_error(&dd->pcidev->dev, dma_addr)) {
+	if (dma_mapping_error(dma_addr)) {
 		ret = -ENOMEM;
 		goto free_unmap;
 	}
@@ -305,7 +305,7 @@ static int qib_user_sdma_pin_pages(const
 				     pages[j], 0, flen, DMA_TO_DEVICE);
 		unsigned long fofs = addr & ~PAGE_MASK;
 
-		if (dma_mapping_error(&dd->pcidev->dev, dma_addr)) {
+		if (dma_mapping_error(dma_addr)) {
 			ret = -ENOMEM;
 			goto done;
 		}
@@ -516,7 +516,7 @@ static int qib_user_sdma_queue_pkts(cons
 		if (page) {
 			dma_addr = dma_map_page(&dd->pcidev->dev,
 						page, 0, len, DMA_TO_DEVICE);
-			if (dma_mapping_error(&dd->pcidev->dev, dma_addr)) {
+			if (dma_mapping_error(dma_addr)) {
 				ret = -ENOMEM;
 				goto free_pbc;
 			}
@@ -686,13 +686,13 @@ static inline __le64 qib_sdma_make_desc0
 
 static inline __le64 qib_sdma_make_first_desc0(__le64 descq)
 {
-	return descq | cpu_to_le64(1ULL << 12);
+	return descq | __constant_cpu_to_le64(1ULL << 12);
 }
 
 static inline __le64 qib_sdma_make_last_desc0(__le64 descq)
 {
 					      /* last */  /* dma head */
-	return descq | cpu_to_le64(1ULL << 11 | 1ULL << 13);
+	return descq | __constant_cpu_to_le64(1ULL << 11 | 1ULL << 13);
 }
 
 static inline __le64 qib_sdma_make_desc1(u64 addr)
@@ -789,7 +789,7 @@ static int qib_user_sdma_push_pkts(struc
 		if (ofs > dd->piosize2kmax_dwords) {
 			for (i = 0; i < pkt->naddr; i++) {
 				ppd->sdma_descq[dtail].qw[0] |=
-					cpu_to_le64(1ULL << 14);
+					__constant_cpu_to_le64(1ULL << 14);
 				if (++dtail == ppd->sdma_descq_cnt)
 					dtail = 0;
 			}
diff -up a/drivers/infiniband/hw/qib/qib_verbs.c b/drivers/infiniband/hw/qib/qib_verbs.c
--- a/drivers/infiniband/hw/qib/qib_verbs.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_verbs.c	2010-04-20 15:58:32.000000000 -0700
@@ -1319,7 +1319,7 @@ static int qib_verbs_send_dma(struct qib
 
 	tx->txreq.addr = dma_map_single(&dd->pcidev->dev, phdr,
 					tx->hdr_dwords << 2, DMA_TO_DEVICE);
-	if (dma_mapping_error(&dd->pcidev->dev, tx->txreq.addr))
+	if (dma_mapping_error(tx->txreq.addr))
 		goto map_err;
 	tx->align_buf = phdr;
 	tx->txreq.flags |= QIB_SDMA_TXREQ_F_FREEBUF;
@@ -1714,7 +1714,7 @@ static int qib_query_port(struct ib_devi
 	u16 lid = ppd->lid;
 
 	memset(props, 0, sizeof(*props));
-	props->lid = lid ? lid : be16_to_cpu(IB_LID_PERMISSIVE);
+	props->lid = lid ? lid : __constant_be16_to_cpu(IB_LID_PERMISSIVE);
 	props->lmc = ppd->lmc;
 	props->sm_lid = ibp->sm_lid;
 	props->sm_sl = ibp->sm_sl;
@@ -2087,7 +2087,7 @@ static void init_ibport(struct qib_pport
 	spin_lock_init(&ibp->lock);
 	/* Set the prefix to the default value (see ch. 4.1.1) */
 	ibp->gid_prefix = IB_DEFAULT_GID_PREFIX;
-	ibp->sm_lid = be16_to_cpu(IB_LID_PERMISSIVE);
+	ibp->sm_lid = __constant_be16_to_cpu(IB_LID_PERMISSIVE);
 	ibp->port_cap_flags = IB_PORT_SYS_IMAGE_GUID_SUP |
 		IB_PORT_CLIENT_REG_SUP | IB_PORT_SL_MAP_SUP |
 		IB_PORT_TRAP_SUP | IB_PORT_AUTO_MIGR_SUP |
@@ -2254,6 +2254,7 @@ int qib_register_ib_device(struct qib_de
 	ibdev->phys_port_cnt = dd->num_pports;
 	ibdev->num_comp_vectors = 1;
 	ibdev->dma_device = &dd->pcidev->dev;
+	ibdev->class_dev.dev = ibdev->dma_device;
 	ibdev->query_device = qib_query_device;
 	ibdev->modify_device = qib_modify_device;
 	ibdev->query_port = qib_query_port;
diff -up a/drivers/infiniband/hw/qib/qib_verbs.h b/drivers/infiniband/hw/qib/qib_verbs.h
--- a/drivers/infiniband/hw/qib/qib_verbs.h	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_verbs.h	2010-04-20 16:39:44.000000000 -0700
@@ -94,13 +94,13 @@ struct qib_verbs_txreq;
 #define IB_PMA_SAMPLE_STATUS_RUNNING    0x02
 
 /* Mandatory IB performance counter select values. */
-#define IB_PMA_PORT_XMIT_DATA   cpu_to_be16(0x0001)
-#define IB_PMA_PORT_RCV_DATA    cpu_to_be16(0x0002)
-#define IB_PMA_PORT_XMIT_PKTS   cpu_to_be16(0x0003)
-#define IB_PMA_PORT_RCV_PKTS    cpu_to_be16(0x0004)
-#define IB_PMA_PORT_XMIT_WAIT   cpu_to_be16(0x0005)
+#define IB_PMA_PORT_XMIT_DATA   __constant_cpu_to_be16(0x0001)
+#define IB_PMA_PORT_RCV_DATA    __constant_cpu_to_be16(0x0002)
+#define IB_PMA_PORT_XMIT_PKTS   __constant_cpu_to_be16(0x0003)
+#define IB_PMA_PORT_RCV_PKTS    __constant_cpu_to_be16(0x0004)
+#define IB_PMA_PORT_XMIT_WAIT   __constant_cpu_to_be16(0x0005)
 
-#define QIB_VENDOR_IPG		cpu_to_be16(0xFFA0)
+#define QIB_VENDOR_IPG		__constant_cpu_to_be16(0xFFA0)
 
 #define IB_BTH_REQ_ACK		(1 << 31)
 #define IB_BTH_SOLICITED	(1 << 23)
@@ -436,6 +436,7 @@ struct qib_qp {
 	spinlock_t s_lock;
 	atomic_t s_dma_busy;
 	unsigned processor_id;	/* Processor ID QP is bound to */
+	unsigned send_proc_id;	/* Preferred processor to send from */
 	u32 s_flags;
 	u32 s_cur_size;         /* size of send packet in bytes */
 	u32 s_len;              /* total length of s_sge */
@@ -813,11 +814,11 @@ extern struct workqueue_struct *qib_wq;
 static inline void qib_schedule_send(struct qib_qp *qp)
 {
 	if (qib_send_ok(qp)) {
-		if (qp->processor_id == smp_processor_id())
+		if (qp->send_proc_id == smp_processor_id())
 			queue_work(qib_wq, &qp->s_work);
 		else
-			queue_work_on(qp->processor_id,
-				      qib_wq, &qp->s_work);
+			queue_delayed_work_on(qp->send_proc_id,
+					      qib_wq, &qp->s_work, 0);
 	}
 }
 
diff -up a/drivers/infiniband/hw/qib/qib_verbs_mcast.c b/drivers/infiniband/hw/qib/qib_verbs_mcast.c
--- a/drivers/infiniband/hw/qib/qib_verbs_mcast.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_verbs_mcast.c	2010-04-20 15:58:32.000000000 -0700
@@ -31,7 +31,8 @@
  * SOFTWARE.
  */
 
-#include <linux/rculist.h>
+#include <linux/list.h>
+#include <linux/rcupdate.h>
 
 #include "qib.h"
 
diff -up a/drivers/infiniband/hw/qib/qib_wc_pat.c b/drivers/infiniband/hw/qib/qib_wc_pat.c
--- a/drivers/infiniband/hw/qib/qib_wc_pat.c	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_wc_pat.c	2010-04-20 15:58:32.000000000 -0700
@@ -171,7 +171,7 @@ static int read_and_modify_pat(void)
 	preempt_disable();
 	rd_old_pat(&ret);
 	if (!ret)
-		smp_call_function(rd_old_pat, &ret, 1);
+		smp_call_function(rd_old_pat, &ret, 1, 1);
 	if (ret)
 		goto out;
 
@@ -182,7 +182,7 @@ static int read_and_modify_pat(void)
 	if (ret)
 		goto out;
 
-	smp_call_function(wr_new_pat, &ret, 1);
+	smp_call_function(wr_new_pat, &ret, 1, 1);
 	BUG_ON(ret); /* have inconsistent PAT state */
 out:
 	preempt_enable();
@@ -196,7 +196,7 @@ static int restore_pat(void)
 	preempt_disable();
 	wr_old_pat(&ret);
 	if (!ret) {
-		smp_call_function(wr_old_pat, &ret, 1);
+		smp_call_function(wr_old_pat, &ret, 1, 1);
 		BUG_ON(ret); /* have inconsistent PAT state */
 	}
 
@@ -206,7 +206,7 @@ static int restore_pat(void)
 
 int qib_enable_wc_pat(void)
 {
-	struct cpuinfo_x86 *c = &cpu_data(0);
+	struct cpuinfo_x86 *c = &(cpu_data)[0];
 	int ret;
 
 	if (wc_enabled)
@@ -246,6 +246,11 @@ pgprot_t pgprot_writecombine(pgprot_t _p
 		pgprot_noncached(_prot);
 }
 
+void __iomem *ioremap_wc(unsigned long phys_addr, unsigned long size)
+{
+	return __ioremap(phys_addr, size, QIB_WC_FLAGS);
+}
+
 int qib_wc_pat_enabled(void)
 {
 	return wc_enabled;
@@ -261,6 +266,11 @@ pgprot_t pgprot_writecombine(pgprot_t _p
 	return pgprot_noncached(_prot);
 }
 
+void __iomem *ioremap_wc(unsigned long phys_addr, unsigned long size)
+{
+	return ioremap_nocache(phys_addr, size);
+}
+
 int qib_wc_pat_enabled(void)
 {
 	return 0;
diff -up a/drivers/infiniband/hw/qib/qib_wc_pat.h b/drivers/infiniband/hw/qib/qib_wc_pat.h
--- a/drivers/infiniband/hw/qib/qib_wc_pat.h	2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/qib_wc_pat.h	2010-04-20 15:58:32.000000000 -0700
@@ -44,5 +44,6 @@ int qib_enable_wc_pat(void);
 void qib_disable_wc_pat(void);
 int qib_wc_pat_enabled(void);
 pgprot_t pgprot_writecombine(pgprot_t _prot);
+void __iomem *ioremap_wc(unsigned long phys_addr, unsigned long size);
 
 #endif
